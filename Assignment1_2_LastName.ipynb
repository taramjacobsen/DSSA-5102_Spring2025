{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c825ca7c",
   "metadata": {},
   "source": [
    "# Assignment #1 - Data Gathering and Warehousing - DSSA-5102"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e792669",
   "metadata": {},
   "source": [
    "Instructor: Melissa Laurino<br>\n",
    "Spring 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9fe204",
   "metadata": {},
   "source": [
    "Name:\n",
    "<br>\n",
    "Date:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292e9143",
   "metadata": {},
   "source": [
    "<b>Data. Is. Everywhere.</b> <br>\n",
    "Our first objective is to locate and explore <b>TWO</b> datasets about something you are passionate about, or related to a field you would like to work in. Our semester plan is <i>try</i> to work with the same dataset through out the semester. You can find and explore as many datasets as you wish, but Assignment #2 will focus on the one you like the best.\n",
    "There are many great websites that offer public datasets avaialable to download. Examples include but are not limited to:\n",
    "<br>\n",
    "Data.gov - https://data.gov/ - has many government owened public datasets.<br>\n",
    "World Bank Data - https://data.worldbank.org/ - has world economic, social, and environmental data.<br>\n",
    "Google Dataset Search - https://datasetsearch.research.google.com/ - many of these available datasets link to published studies available on Google Scholar in many fields.<br>\n",
    "Kaggle Datasets - https://www.kaggle.com/datasets - a platform for sharing datasets. Anyone can upload to this website.<br>\n",
    "U.S. Census Bureau - https://www.census.gov/ - data on people, places and econoy for the United States.\n",
    "GitHub - https://github.com/ - hosts datasets and completed projects.<br>\n",
    "Federal Reserve Economic Data (FRED) - https://fred.stlouisfed.org/ - Financial and economic data.<br>\n",
    "CDC - https://data.cdc.gov/ - Explore the various data collected by the CDC.<br>\n",
    "NOAA - https://www.ncei.noaa.gov/cdo-web/ - NOAA climate and ocean data. <br>\n",
    "<br>\n",
    "In addition to these resources, occasionally local organizations may be able to provide you with data, or maybe even your own company! Your data source can come from a personal connection, but please be mindful of any data agreements or approvals you may need. If you need approval to use data from your place of employment, please specify that with the instructor so we can ensure no violations to your data agreement will be made this semester.\n",
    "<br>\n",
    "<br>\n",
    "Resources for learning Python:\n",
    "- Data camp - https://www.datacamp.com/category/python - Contact Professor Baldwin for access.<br>\n",
    "- Data Science from Scratch: First Principles with Python - Check Blackboard <br>\n",
    "- Python for Data Analysis Data Wrangling with pandas, NumPy & Jupyter - Check Blackboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712dad64-6ed8-4680-90b7-4e47833e6887",
   "metadata": {},
   "source": [
    "For Assignment #1, our objective is to locate and explore two different datasets using Python. We will choose one of these datasets to clean to prepare for our future database. For each dataset include: <br>\n",
    "- The dataset name, company/organization resonsible for data collection, the download link, and date of access. <br>\n",
    "- Load neccessary packages <br>\n",
    "- Obtain the general info for your data such as size, number of rows/columns, column names, describing the data etc. <br>\n",
    "- What are the unique columns or variables present in your dataset? <br>\n",
    "- Create one quick plot to visualize your data. It is okay if it is messy since your data has not been cleaned yet, but still make sure you are practicing good graphins with a title, axis labels, and anything else needed for your graph.  <br>\n",
    "\n",
    "Comment ALL code to recieve full credit. The above bullet points are to help guide you in your process, but extensive exploration is expected for each data set. <br>\n",
    "<br>\n",
    "Explore various markdown font settings: https://ingeh.medium.com/markdown-for-jupyter-notebooks-cheatsheet-386c05aeebed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5eadb4",
   "metadata": {},
   "source": [
    "## Dataset #1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf03c2c",
   "metadata": {},
   "source": [
    "<b>Dataset name: </b><br>\n",
    "<b>Company/Government Organization: </b><br>\n",
    "Download link:  <br>\n",
    "Date of Access: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a352bf",
   "metadata": {},
   "source": [
    "Popular packages to load in working with Python: <br>\n",
    "pandas: https://pandas.pydata.org/about/index.html <br>\n",
    "numpy: https://numpy.org/learn/ <br>\n",
    "matplotlib: https://matplotlib.org/stable/api/pyplot_summary.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f274f2ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# My examples are below, but edit as needed to fit your dataset:\n",
    "import pandas as pd # Reads, writes, shapes, manipulates data\n",
    "import numpy as np # Basic stats and numerical operations\n",
    "import matplotlib.pyplot as plt # Creating basic graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c86913",
   "metadata": {},
   "source": [
    "Importing a library as an abbreviation is beneficial to shorten your code and make it more concise. <br>\n",
    "For example, when referencing your data frame without the abbreviation you would write: pandas.DataFrame <br>\n",
    "With an abbreviation, you can just write: pd.DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7e9968-efb1-482d-b7f7-c309228fbbde",
   "metadata": {},
   "source": [
    "Load your chosen dataset into the notebook below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8dbcdffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be sure to document each line of code like the above example.\n",
    "# Documenting each line of code is helpful when revisiting assignments later in the semester."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fc0d288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the locally stored CSV file as a dataframe\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d345116-947c-4fa3-ac6f-435a8ea06fcb",
   "metadata": {},
   "source": [
    "We can run df.info() to see how large the dataframe is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfe1d023-2f96-48af-945a-95ce54d937e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7959c595-f3be-4277-8b84-e0aaa92bfd53",
   "metadata": {},
   "source": [
    "I have X columns in my dataset. \n",
    "I have X rows in my dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed08a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f944fe78-56d8-43af-9677-819b6ead3c10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7c5040-0da2-4c7a-8877-faec68d16c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0124b1b5-b9ce-41eb-8833-9c109f3c7b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "987f5f28-923c-4687-96d8-27867ea6a27b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "49dd7a12-f482-497d-9d1a-703932ec7730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "741d90c8",
   "metadata": {},
   "source": [
    "What are the unique columns or variables present in your dataset? How many rows are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b0ba15e-1210-4114-992b-157d5ebfa9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the unique column names?\n",
    "\n",
    "# Find and print the total number of columns\n",
    "\n",
    "# Find and print the total number of rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24b6448-b634-4b7a-9c69-f9a9353cb354",
   "metadata": {},
   "source": [
    "Use print(\" \") statements in python to print text or variables in the output. <br>\n",
    "Use \\n in the print statement to skip a line. Without skipping a line, everything prints close together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26525152-01c2-43ce-8b4d-1720a337892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the numerical columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65652edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look more closely at the data types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e554c1a0-9002-4b0a-98fd-02e52156ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the values of a category column:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b913643b",
   "metadata": {},
   "source": [
    "Create one graph to quickly visualize your data using matplotlib. <br>\n",
    "Matplotlib color guide: https://i.sstatic.net/lFZum.png <br><br>\n",
    "It's okay if it is not visualy appealing or contains outliers, because we have not cleaned our data yet! Did you get any errors? If so, what were they? Would the errors have been avoided if you had cleaned the data first?<br>\n",
    "Data cleaning and transforming is very important when storing your data in a warehouse...ready for Assignment #2?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251688bc-3597-4eec-b1e1-c1e24e090b93",
   "metadata": {},
   "source": [
    "## Dataset #2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ba6fbf-6c3e-469e-bf3a-49fb9d16fc84",
   "metadata": {},
   "source": [
    "<b>Dataset name: </b><br>\n",
    "<b>Company/Government Organization: </b><br>\n",
    "Download link:  <br>\n",
    "Date of Access: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f74168-7ca6-4c93-8f2b-2b6892c7a8cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efa3d9f-e6ae-4c62-8517-1ef603939315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddf3b8b-b39a-4785-952b-f271b226c8c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbfba8d-8065-4def-978d-0d5cf33b825f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50932d62-30f3-4ed6-9d80-af56240bec7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4d3430-3001-4a06-a7e6-2a9728fa0b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce986ef-0427-41d8-8e7f-edccc11fef22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7f937a-70fc-4b92-9a2a-2402a09b9d24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fce6b1d-9b2a-4f48-84b6-8ee79d89f94e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b817704-977a-4818-bbfa-77b9d749f7d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ce67fcf",
   "metadata": {},
   "source": [
    "# Assignment #2 - Data Gathering and Warehousing - DSSA-5102\n",
    "\n",
    "Instructor: Melissa Laurino</br>\n",
    "Spring 2025</br>\n",
    "\n",
    "Our next objective is to choose <b>ONE</b> of the datasets from our previous assignment to explore further. The datasets we have chose for Assignment #1 can be cleaned by practicing our Python skills. Depending on your data, and especially the size of it, it may be more beneficial to clean in a language you are comfortable working in already instead of cleaning our data with a new language like SQL. SQL may be needed for cleaning of databases that are very large or hundreds of terabytes in size. We will clean our datasets first before we attempt to load them into our SQL databases. </br>\n",
    "Not only is data everywhere, but it can also be messy. Messy data can originate in the data collection process, whether this is occurring with manual data entry and typos, or with outdated collection forms that hold multiple variables that mean the same thing. For example, while collecting data on marine mammals, it is important to note who the observer is. With Python and R, reading excel or csv files, these languages will take the same variable written as, \"Melissa Laurino\" and \"melissa laurino\" as two separate observers because they are case sensitive. However, this is not accurate because they are meant to be the same person within the observer column or category.</br>\n",
    "Clean data is important for consistency that leads to accurate results and analysis. If we are using our data to make informed decisions in our field, we need it to be clean. We do not want to omit rows that may make a difference to our dataset because they do not fit a certain criteria due to typos, but how much should the original dataset be altered? Depending on your field, there may be regulations and compliance standards regarding data quality. Protocols may state if the data does not read exactly how it should be, then it should be ommitted. </br>\n",
    "For our learning objectives in this class, we will clean our data. Our first assignment in our warehousing journey was important because it allowed us to gain a better understanding of a dataset that we personally did not collect. Now that we have that understanding, we can explore it in greater depth and clean it as necessary.<br>\n",
    "<br>\n",
    "For Assignment #2, our objective is to clean one of the datasets explored above using Python to prepare for our future database from scratch. Include at a minimum:\n",
    "\n",
    "- The chosen dataset name, company/organization resonsible for data collection, the download link, and date of access.\n",
    "- Load neccessary packages and data (Only if you start a new session in Jupyter, not if you are continuing from above).\n",
    "- Make all column names lower case, contain no spaces, and no special characters (SQL will not like this otherwise).\n",
    "- *Make detailed comments with your code* <br>\n",
    "- *Record EVERYTHING ommitted and changed if necessary* <br>\n",
    "- Since we are exploring and learning without a specific organization policy, use your best judgement when ommitting records. If you have chosen to ommit data, please explain why.</br>\n",
    "- Save your new CLEAN data as a .csv file. \n",
    "\n",
    "\n",
    "Comment ALL code to recieve full credit. The above bullet points are to help guide you in your process, but extensive cleaning is expected for your data set (This will also save you a lot of time down the line!). \n",
    "<br>\n",
    "\n",
    "<br>\n",
    "<b>The code that I have written below is just to give you ideas on exploring and cleaning data. It is encouraged that you explore and clean it in greater detail than what I have written below for full credit.</b><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07cb638-34d9-4342-92bb-f405ae1789cd",
   "metadata": {},
   "source": [
    "<b>Dataset name: </b><br>\n",
    "<b>Company/Government Organization: </b><br>\n",
    "Download link:  <br>\n",
    "Date of Access: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a707f9e0-68fe-4304-8bbe-a13921b7bf78",
   "metadata": {},
   "source": [
    "Why did you choose to continue working with this dataset? <br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671734a8-46a4-4d71-81e7-ce3c62f716b4",
   "metadata": {},
   "source": [
    "Make all column names lowercase, with no spaces or special characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79bf2359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make column names lowercase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6ab7e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Happy Cleaning :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96de4afc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb86068e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e6e8b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb333a28-a23b-40d6-b273-b2b6e2549179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738acfbc-9371-4eb2-89f6-377d56bc0e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fb688b-a75b-4c29-a085-21b2507e10d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea083254-a65e-4ebe-b136-b18961266f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dd64aa-42a0-49f5-adc5-2fac9e4d105e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7524c2-a52f-481d-943c-0bb4a418b5de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
